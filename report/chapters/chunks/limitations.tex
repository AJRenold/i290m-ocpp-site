\subsection{Limitations}
\label{sec:limitations}

Our survey is sample is small ($n=24$), and therefore the statistical analysis should be considered more indicatory than rigorous analysis. Furthermore, as several students have participated in the same projects, those projects have several entries in our data. This implies our data is skewed towards these projects, especially peerlibrary (n=5) and hypothes.is (n=3).

Furthermore, after reviewing the results in the class, the survey was found inaquent in severals ways. First and foremost, it was biased towards software development, where as some participants were involved in other types of projects. Also exact questions were found difficult, such as the licencing question (\#nn), speaking of licence families and missing major licences such as Apache licence, and number of female contributors (\#nn) found hard to answer. I\footnote{Matti} attribute these problems to the rather cauothic process of contributions and not enough quality control in the end, many problems discussed also in the previous efforts of academic collaboration \cite{Tomlinson2012}. I suggest that in the future, instead of circa 20 participants editing the survey there should be a (benefictous) dictator chosen to coordinate the collaboration effort.